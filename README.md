# ðŸ“° Fake News Detection â€“ NLP Task

### ðŸš€ **ELEVVO Internship Project**

* ðŸ‘¤ **Author:** Ali Muhammed  
* ðŸ§  **Task Level:** 2  
* ðŸš€ **Task Number:** 3

---

## ðŸŽ¯ **Objective**
Build a machine learning model to classify news articles as **Real** âœ… or **Fake** âŒ using Natural Language Processing (NLP) techniques.

---

## ðŸ“ **Dataset**

* **Files:** `train.csv`, `test.csv`  
* **Columns Used:**
  * `title`  (Text)  
  * `text`  (Text)
  * `subject`  (Text)
  * `date`  (datetime)
  * `label` (Binary target: `fake` / `real`)
* **Rows Used:** All **\~44,898 reviews** from the dataset

---

## ðŸ›  **Tools & Libraries**
* ðŸ Python  
* ðŸ“Š Pandas  
* ðŸ”¡ re (Regular Expressions)  
* âœ‚ï¸ NLTK  
* ðŸ”¢ Collections  
* ðŸ“ˆ Matplotlib  
* â˜ï¸ WordCloud  
* ðŸ¤– Scikit-learn  

---

## ðŸ”„ **Workflow Overview**

### ðŸ§¹ **1. Data Cleaning & Preprocessing**
* ðŸ”¡ Converted text to lowercase  
* ðŸš« Removed stopwords and applied lemmatization  
* âœ‚ï¸ Tokenized text where needed for analysis

---

### âœ¨ **2. Feature Extraction**
* ðŸ§® Used **TF-IDF Vectorizer** to convert text into numerical features for the model.

---

### ðŸ§  **3. Model Building**
* ðŸ” Used Logistic Regression Model and Multinomial Naive Bayes Model (Bonus) as the classification algorithms
* ðŸ—‚ï¸ Split dataset into 80% training and 20% testing

---

### ðŸ“Š **4. Model Evaluation**
* ðŸ“‘ Used metrics like **Accuracy**, **Confusion Matrix**, **Classification Report** and **F1 Score**

---

## ðŸŽ¨ **Visualizations**
* â˜ï¸ Generated WordCloud showing the **most frequent words** in news articles.

---

## ðŸ“Š **Model Insights**

| **ðŸ’¡ Model**         | **ðŸ§© Type**          | **ðŸŽ¯ Accuracy** |
| ----------------- | ----------------- | ------------ |
| ðŸ“ˆ Logistic Regression        | Classical ML      | ~99% âœ…         |

---

## ðŸ’¡ **Key Learnings**

* Multi-class classification using classical methods
* Text preprocessing and feature engineering  
* Evaluating and visualizing NLP models  

---

> **Note:** This task focused on classic NLP (no deep learning) to strengthen fundamental understanding before moving to advanced transformer models.

